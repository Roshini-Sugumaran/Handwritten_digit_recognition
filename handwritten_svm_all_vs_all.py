# -*- coding: utf-8 -*-
"""handwritten_svm_all vs all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oKYNnaysIsp1u8mBFNqNiOLAjObuegdg
"""

from google.colab import drive

# Step 2: Mount Google Drive
drive.mount('/content/drive')

import numpy as np
from keras.datasets import mnist

def encodeY(Y_smallTrain, cls):
    Y_BinaryList = np.where(Y_smallTrain == cls, 1, -1)
    return Y_BinaryList

def pegasos(X_smallTrain, yTrainBinary, lamda, iteration):
    ns, nf = X_smallTrain.shape
    w = np.zeros(nf)
    for t in range(iteration):
        nt = 1 / (lamda * (t + 1))
        i = np.random.randint(low=0, high=ns)
        condition = yTrainBinary[i] * np.dot(X_smallTrain[i], w)
        factor = (1 - nt * lamda) * w
        if condition < 1:
            addFactor = nt * yTrainBinary[i] * X_smallTrain[i]
            w = factor + addFactor
        else:
            w = factor
    return w

def trainSvm(X_smallTrain, Y_smallTrain, classes):
    wClassList = []
    for cls in classes:
        yTrainBinary = encodeY(Y_smallTrain, cls)
        wClass = pegasos(X_smallTrain, yTrainBinary, lamda=0.001, iteration=100000)
        wClassList.append(wClass)
        print(f"Trained class {cls}")
    return wClassList

def testX(X_smallTest, wClassList):
    ns, nf = X_smallTest.shape
    yPredict = np.zeros(ns, dtype=int)
    for i in range(ns):
        yTemp = -float('inf')
        for j in range(len(wClassList)):
            yValue = np.dot(wClassList[j], X_smallTest[i])
            if yValue > yTemp:
                yTemp = yValue
                yClass = j
        yPredict[i] = yClass
    return yPredict

def calculateOverallAccuracy(Y_smallTest, yPredict, classes):
    confusionMatrix = np.zeros((len(classes), len(classes)), dtype=int)
    count = np.sum(Y_smallTest == yPredict)
    for i in range(len(Y_smallTest)):
        confusionMatrix[int(Y_smallTest[i]), int(yPredict[i])] += 1
    accuracy = (count / len(Y_smallTest)) * 100
    return accuracy, confusionMatrix

# Load data
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()
Train_X = X_train.reshape(60000, 784)
Test_X = X_test.reshape(10000, 784)

# Combine and shuffle data
total_data = np.zeros((70000, 785))
total_data[:60000, :-1] = Train_X
total_data[60000:, :-1] = Test_X
total_data[:60000, -1] = Y_train
total_data[60000:, -1] = Y_test

numOfIteration = 1
averageAccuracyArray = np.zeros(numOfIteration)

for iterationCount in range(numOfIteration):
    np.random.shuffle(total_data)

    # Reduce the sample size for debugging
    X_trainSize = 60000
    X_testSize = 10000
    Train_X = total_data[:60000, :-1]
    Test_X = total_data[60000:, :-1]
    Y_train = total_data[:60000, -1]
    Y_test = total_data[60000:, -1]

    X_smallTrain = Train_X[0:X_trainSize]
    Y_smallTrain = Y_train[0:X_trainSize]
    X_smallTest = Test_X[0:X_testSize]
    Y_smallTest = Y_test[0:X_testSize]

    classes = np.unique(Y_smallTrain)

    wClassList = trainSvm(X_smallTrain, Y_smallTrain, classes)
    yPredict = testX(X_smallTest, wClassList)
    accuracy, confusionMatrix = calculateOverallAccuracy(Y_smallTest, yPredict, classes)

    averageAccuracyArray[iterationCount] = accuracy
    print(f"Iteration {iterationCount}: Accuracy = {accuracy:.2f}%")
    print(confusionMatrix)

averageAccuracy = np.mean(averageAccuracyArray)
print('*************** Average Accuracy ************************')
print(f"{averageAccuracy:.2f}%")